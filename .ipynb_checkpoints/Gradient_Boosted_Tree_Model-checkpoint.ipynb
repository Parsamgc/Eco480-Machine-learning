{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87cf2ea6-8b8f-400c-be20-77ac7e1e9012",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modules\n",
    "import inspect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import inspect\n",
    "import warnings\n",
    "\n",
    "from sklearn import ensemble, metrics, model_selection, preprocessing, tree\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, explained_variance_score, max_error, median_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from matplotlib import pyplot\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.inspection import PartialDependenceDisplay\n",
    "\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b8a6375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_roc(fp_rates:np.ndarray, tp_rates:np.ndarray, thresholds:np.ndarray, best_index:int=None) -> None:\n",
    "    '''Displays ROC curve and AUC'''\n",
    "    auc     = metrics.auc(fp_rates, tp_rates)\n",
    "    fig, ax = pyplot.subplots(1, figsize=(5, 5))\n",
    "    ax.plot(fp_rates, tp_rates, color='blue', label=f'AUC: {auc:0.4f}')\n",
    "    ax.plot([0, 1], [0, 1], color='red', linestyle='dashed')\n",
    "    if best_index is not None:\n",
    "        ax.scatter(fp_rates[best_index], tp_rates[best_index], marker='o', c='lightgreen', s=7.5**2, edgecolor='black', zorder=2, label=f'Threshold: {thresholds[best_index]:0.4f}')\n",
    "    ax.set_title('Receiver operating characteristic')\n",
    "    ax.set_xlabel('False positive rate')\n",
    "    ax.set_ylabel('True positive rate')\n",
    "    ax.legend(loc='lower right', frameon=False)\n",
    "    pyplot.tight_layout()\n",
    "    pyplot.show()\n",
    "\n",
    "def display_history(history:dict, stat:str='loss', validation:bool=False) -> None:\n",
    "    '''Displays training history for a statistic'''\n",
    "    fig, ax = pyplot.subplots(1, figsize=(5, 5))\n",
    "    ax.plot(history[stat], label='Training sample')\n",
    "    if validation:\n",
    "        ax.plot(history[f'val_{stat}'], label='Validation sample')\n",
    "    ax.set_title(f'Model training', fontsize=15)\n",
    "    ax.set_ylabel(stat.title())\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.legend(frameon=False)\n",
    "    pyplot.tight_layout()\n",
    "    pyplot.show()\n",
    "    \n",
    "def f1_score(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    \n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    \n",
    "    f1 = 2 * ((precision * recall) / (precision + recall + K.epsilon()))\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3946eb09-6ce3-4fcf-8856-8ecc26af8b92",
   "metadata": {},
   "source": [
    "## Gradient Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b411854-9919-476e-ae08-560a12b7f2f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import the data\n",
    "df_selected = pd.read_csv('Data_selection.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "842c4282-1946-41ab-969e-ea7618ec733c",
   "metadata": {},
   "source": [
    "##### 1.1 Initial Fitting on data set with preliminary feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1181b2ff-d351-448c-9e74-8ab55b5afb3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Training</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.651623</td>\n",
       "      <td>0.658654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.655066</td>\n",
       "      <td>0.139907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.640523</td>\n",
       "      <td>0.624940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.647713</td>\n",
       "      <td>0.228630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROC AUC</td>\n",
       "      <td>0.651623</td>\n",
       "      <td>0.643282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric  Training      Test\n",
       "0   Accuracy  0.651623  0.658654\n",
       "1  Precision  0.655066  0.139907\n",
       "2     Recall  0.640523  0.624940\n",
       "3   F1-score  0.647713  0.228630\n",
       "4    ROC AUC  0.651623  0.643282"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df_selected\n",
    "\n",
    "# Randomly split the data set into training and testing and deal with the imbalanced dependent variable using SMOTE\n",
    "y = df['TARGET']\n",
    "X = df.drop('TARGET', axis=1)\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size = 0.75, shuffle = True, random_state = 480)\n",
    "\n",
    "undersampler = RandomUnderSampler(random_state=480)\n",
    "X_train_resampled, y_train_resampled = undersampler.fit_resample(X_train, y_train)\n",
    "X_test_resampled, y_test_resampled = undersampler.fit_resample(X_test, y_test)\n",
    "\n",
    "X_train_resampled.columns = [col.replace('[', '').replace(']', '').replace('<', '') for col in X_train_resampled.columns]\n",
    "X_test.columns = [col.replace('[', '').replace(']', '').replace('<', '') for col in X_test.columns]\n",
    "\n",
    "# Fit an XGBoost model with 25 trees to the training data\n",
    "XGBModel = GradientBoostingClassifier(n_estimators=25, random_state=480)\n",
    "XGBModel.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# make predictions on the training and test sets\n",
    "y_pred_train = XGBModel.predict(X_train_resampled)\n",
    "y_pred_test = XGBModel.predict(X_test)\n",
    "\n",
    "# compute in-sample performance metrics\n",
    "accuracy_train = metrics.accuracy_score(y_train_resampled, y_pred_train)\n",
    "precision_train = metrics.precision_score(y_train_resampled, y_pred_train)\n",
    "recall_train = metrics.recall_score(y_train_resampled, y_pred_train)\n",
    "f1_score_train = metrics.f1_score(y_train_resampled, y_pred_train)\n",
    "roc_auc_train = metrics.roc_auc_score(y_train_resampled, y_pred_train)\n",
    "\n",
    "# compute out-of-sample performance metrics\n",
    "accuracy_test = metrics.accuracy_score(y_test, y_pred_test)\n",
    "precision_test = metrics.precision_score(y_test, y_pred_test)\n",
    "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
    "f1_score_test = metrics.f1_score(y_test, y_pred_test)\n",
    "roc_auc_test = metrics.roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "# assuming you have already computed the performance metrics\n",
    "data = {'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-score', 'ROC AUC'],\n",
    "        'Training': [accuracy_train, precision_train, recall_train, f1_score_train, roc_auc_train],\n",
    "        'Test': [accuracy_test, precision_test, recall_test, f1_score_test, roc_auc_test]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "069e6cd7-ddd2-4ee5-80c5-3fa6f93e7c5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Training</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.590234</td>\n",
       "      <td>0.584248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAE</td>\n",
       "      <td>0.348377</td>\n",
       "      <td>0.341346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric  Training      Test\n",
       "0   RMSE  0.590234  0.584248\n",
       "1    MAE  0.348377  0.341346"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_train = mean_squared_error(y_train_resampled, y_pred_train, squared = False)\n",
    "mae_train = mean_absolute_error(y_train_resampled, y_pred_train)\n",
    "\n",
    "rmse_test = mean_squared_error(y_test, y_pred_test, squared = False)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "data = {'Metric': ['RMSE', 'MAE'],\n",
    "        'Training': [rmse_train, mae_train],\n",
    "        'Test': [rmse_test, mae_test]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea53c44-07e3-4006-8d8d-1116f53ad4e2",
   "metadata": {},
   "source": [
    "##### 1.2 Hyperparameter Tuning using Cross-validation on data set with preliminary feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0026d0b-5646-4abb-9ad3-2d4abc0a37db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# define the parameter grid\n",
    "param_grid = {\n",
    "    'max_depth': [3, 6, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'subsample': [0.5, 0.8, 1], \n",
    "    'max_features': [None, 'sqrt', 'log2'],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 5, 10]\n",
    "}\n",
    "\n",
    "# create a gradient boosted tree model\n",
    "gbt = GradientBoostingClassifier(random_state=480)\n",
    "\n",
    "# create a grid search object\n",
    "grid_search = GridSearchCV(estimator=gbt, param_grid=param_grid, cv=5)\n",
    "\n",
    "# fit the grid search object to the data\n",
    "grid_search.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e087ab-20ce-466f-bd21-0ad3ee125d49",
   "metadata": {},
   "source": [
    "##### 1.3 Refit the model using optimal parameters found through hyperparameter tuning on data set with preliminary feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b05fbf43-77d2-49ec-ba1c-4e32e5f60845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Training</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.685491</td>\n",
       "      <td>0.674003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.687497</td>\n",
       "      <td>0.151220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.680142</td>\n",
       "      <td>0.656275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>F1-score</td>\n",
       "      <td>0.683799</td>\n",
       "      <td>0.245802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ROC AUC</td>\n",
       "      <td>0.685491</td>\n",
       "      <td>0.665920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Metric  Training      Test\n",
       "0   Accuracy  0.685491  0.674003\n",
       "1  Precision  0.687497  0.151220\n",
       "2     Recall  0.680142  0.656275\n",
       "3   F1-score  0.683799  0.245802\n",
       "4    ROC AUC  0.685491  0.665920"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = GradientBoostingClassifier(random_state=480, max_depth = 3, learning_rate = 0.2, n_estimators = 100, subsample = 1, max_features = None, min_samples_split = 10, min_samples_leaf = 1)\n",
    "\n",
    "# fit the model to the training data\n",
    "rf.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# make predictions on the training and test sets\n",
    "y_pred_train = rf.predict(X_train_resampled)\n",
    "y_pred_test = rf.predict(X_test)\n",
    "\n",
    "# compute in-sample performance metrics\n",
    "accuracy_train = metrics.accuracy_score(y_train_resampled, y_pred_train)\n",
    "precision_train = metrics.precision_score(y_train_resampled, y_pred_train)\n",
    "recall_train = metrics.recall_score(y_train_resampled, y_pred_train)\n",
    "f1_score_train = metrics.f1_score(y_train_resampled, y_pred_train)\n",
    "roc_auc_train = metrics.roc_auc_score(y_train_resampled, y_pred_train)\n",
    "\n",
    "# compute out-of-sample performance metrics\n",
    "accuracy_test = metrics.accuracy_score(y_test, y_pred_test)\n",
    "precision_test = metrics.precision_score(y_test, y_pred_test)\n",
    "recall_test = metrics.recall_score(y_test, y_pred_test)\n",
    "f1_score_test = metrics.f1_score(y_test, y_pred_test)\n",
    "roc_auc_test = metrics.roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "# assuming you have already computed the performance metrics\n",
    "data = {'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-score', 'ROC AUC'],\n",
    "        'Training': [accuracy_train, precision_train, recall_train, f1_score_train, roc_auc_train],\n",
    "        'Test': [accuracy_test, precision_test, recall_test, f1_score_test, roc_auc_test]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d23055fe-f8b0-4e28-8d4b-20fdf060af32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metric</th>\n",
       "      <th>Training</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>0.560811</td>\n",
       "      <td>0.570961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAE</td>\n",
       "      <td>0.314509</td>\n",
       "      <td>0.325997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Metric  Training      Test\n",
       "0   RMSE  0.560811  0.570961\n",
       "1    MAE  0.314509  0.325997"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_train = mean_squared_error(y_train_resampled, y_pred_train, squared = False)\n",
    "mae_train = mean_absolute_error(y_train_resampled, y_pred_train)\n",
    "\n",
    "rmse_test = mean_squared_error(y_test, y_pred_test, squared = False)\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "\n",
    "data = {'Metric': ['RMSE', 'MAE'],\n",
    "        'Training': [rmse_train, mae_train],\n",
    "        'Test': [rmse_test, mae_test]}\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "684d9455",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- AMT_CREDIT_MAX_OVERDUE_(-0.001, 861.375]\n- AMT_CREDIT_SUM_(-0.001, 142204.5]\n- AMT_CREDIT_SUM_(142204.5, 315000.0]\n- AMT_CREDIT_SUM_(4226032.71, 1017957917.0]\n- AMT_CREDIT_SUM_DEBT_(-6981558.211, 0.0]\n- ...\nFeature names seen at fit time, yet now missing:\n- AMT_CREDIT_MAX_OVERDUE_(-0.001, 861.375\n- AMT_CREDIT_SUM_(-0.001, 142204.5\n- AMT_CREDIT_SUM_(142204.5, 315000.0\n- AMT_CREDIT_SUM_(4226032.71, 1017957917.0\n- AMT_CREDIT_SUM_DEBT_(-6981558.211, 0.0\n- ...\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# ROC curve\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m yh_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msqueeze(\u001b[43mrf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test_resampled\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      3\u001b[0m fp_rates, tp_rates, thresholds \u001b[38;5;241m=\u001b[39m metrics\u001b[38;5;241m.\u001b[39mroc_curve(y_test_resampled, yh_test)\n\u001b[0;32m      4\u001b[0m youden \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(tp_rates \u001b[38;5;241m-\u001b[39m fp_rates)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1308\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1294\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict class for X.\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m \n\u001b[0;32m   1296\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1306\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[0;32m   1307\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1308\u001b[0m     raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1309\u001b[0m     encoded_labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_loss\u001b[38;5;241m.\u001b[39m_raw_prediction_to_decision(raw_predictions)\n\u001b[0;32m   1310\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(encoded_labels, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py:1261\u001b[0m, in \u001b[0;36mGradientBoostingClassifier.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1243\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Compute the decision function of ``X``.\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m \n\u001b[0;32m   1245\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;124;03m        array of shape (n_samples,).\u001b[39;00m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1261\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1262\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1263\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1264\u001b[0m     raw_predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_predict(X)\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m raw_predictions\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:548\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    484\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    485\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    489\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    490\u001b[0m ):\n\u001b[0;32m    491\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    492\u001b[0m \n\u001b[0;32m    493\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    547\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 548\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    550\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    551\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    552\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    554\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py:481\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    477\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    479\u001b[0m     )\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- AMT_CREDIT_MAX_OVERDUE_(-0.001, 861.375]\n- AMT_CREDIT_SUM_(-0.001, 142204.5]\n- AMT_CREDIT_SUM_(142204.5, 315000.0]\n- AMT_CREDIT_SUM_(4226032.71, 1017957917.0]\n- AMT_CREDIT_SUM_DEBT_(-6981558.211, 0.0]\n- ...\nFeature names seen at fit time, yet now missing:\n- AMT_CREDIT_MAX_OVERDUE_(-0.001, 861.375\n- AMT_CREDIT_SUM_(-0.001, 142204.5\n- AMT_CREDIT_SUM_(142204.5, 315000.0\n- AMT_CREDIT_SUM_(4226032.71, 1017957917.0\n- AMT_CREDIT_SUM_DEBT_(-6981558.211, 0.0\n- ...\n"
     ]
    }
   ],
   "source": [
    "# ROC curve\n",
    "yh_test = np.squeeze(rf.predict(X_test_resampled))\n",
    "fp_rates, tp_rates, thresholds = metrics.roc_curve(y_test_resampled, yh_test)\n",
    "youden = np.argmax(tp_rates - fp_rates)\n",
    "display_roc(fp_rates, tp_rates, thresholds, youden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d15c8a-b64a-433b-acbe-af3537ac3af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and reshape confusion matrix data\n",
    "matrix = confusion_matrix(y_test, y_pred_test)\n",
    "matrix = matrix.astype('float') / matrix.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Build the plot\n",
    "pyplot.figure(figsize=(16,7))\n",
    "sns.set(font_scale=1.4)\n",
    "sns.heatmap(matrix, annot=True, annot_kws={'size':10},\n",
    "            cmap=pyplot.cm.Greens, linewidths=0.2)\n",
    "\n",
    "# Add labels to the plot\n",
    "class_names = ['TARGET = 0', 'TARGET = 1']\n",
    "tick_marks = np.arange(len(class_names))\n",
    "tick_marks2 = tick_marks + 0.5\n",
    "pyplot.xticks(tick_marks, class_names, rotation=25)\n",
    "pyplot.yticks(tick_marks2, class_names, rotation=0)\n",
    "pyplot.xlabel('Predicted label')\n",
    "pyplot.ylabel('True label')\n",
    "pyplot.title('Confusion Matrix for Random Forest Model')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fdcffa3-a99b-4851-8ae1-2f00482ec31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# Create a DataFrame to store the results\n",
    "importance_df = pd.DataFrame({'Feature': X_train_resampled.columns, 'Importance': importances})\n",
    "\n",
    "# Sort the DataFrame by importance and select the top 10 features\n",
    "importance_df = importance_df.sort_values(by='Importance', ascending=False).head(10)\n",
    "\n",
    "# Display the results\n",
    "importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3592c58b-7200-4ed6-bdb5-053c1445f181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get feature importances\n",
    "importances = rf.feature_importances_\n",
    "\n",
    "# get indices of top 10 features\n",
    "indices = np.argsort(importances)[::-1][:10]\n",
    "\n",
    "# calculate partial dependence\n",
    "fig, ax = pyplot.subplots(2, 5, figsize=(20, 5))\n",
    "pdp_results = PartialDependenceDisplay.from_estimator(rf, X_train_resampled, indices,\n",
    "                                                      feature_names=X_train_resampled.columns,\n",
    "                                                      ax=ax.ravel())\n",
    "pyplot.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
